# **Рецензия на статью Денисова Егора “Адаптация методов обучения с подкреплением в задаче обучения LLM”**

## Автор: Акопова Елена

Статья посвящена исследованию методов совмещения обучения с учителем (SFT) и обучения с подкреплением (RL) при дообучении больших языковых моделей. Работа рассматривает адаптацию подходов RLHF и использование комбинированных функций потерь, а также проверяет влияние энтропийной регуляризации на стабильность и итоговое качество модели. 

В целом статья представляет собой понятное и аккуратное исследование, посвящённое важной и актуальной проблеме — стабильности и эффективности RL при обучении моделей небольшого размера. Работа имеет логичную структуру, включает обзор литературы, формальную постановку задачи, описание метода и экспериментальную часть.

Однако для статьи в научном формате, особенно ориентированной на публикацию, заметны недочёты: неполная проработка методологии, недостаточная детализация экспериментов, отсутствие статистических оценок и анализа чувствительности, а также слабая новизна предложенного подхода по сравнению с существующими работами. Ниже приводится детальный разбор.

---

К достоинствам работы можно отнести актуальность. В статье исследуется одно из наиболее важных направлений развития современных LLM — совмещение SFT и RL в задачах рассуждения. Проблема нестабильности RL на небольших моделях действительно актуальна и хорошо мотивирована. Статья имеет чёткую структуру и формальную постановку, аккуратно разделена на логические блоки: постановка задачи, математическое описание функций потерь, алгоритм, экспериментальная часть. Формулы и обозначения представлены ясно. Приводятся результаты современных бейзлайнов (ReLIFT, SuperRL, DeepSeekMath), что помогает контекстуализировать работу. Результаты показывают, что даже небольшая модель при сочетании SFT и RL с энтропийной регуляризацией может достигать значимого улучшения качества. Это ценно для исследовательских групп с ограниченными вычислительными ресурсами.

---

Однако представленная статья содержит также некоторые недостатки. Предложенные методы — чередование SFT и RL, комбинированная функция потерь, энтропийная регуляризация — давно используются в работах по RLHF, PPO и GRPO. В статье отсутствует чёткое объяснение, в чём именно заключается новизна метода. Не хватает информации для воспроизводимости экспериментов: используемые параметры ε, β, γ, величина наград; количество шагов обучения, размер батчей и так далее. Без этих деталей эксперименты трудно воспроизвести. Желательно приводить результаты в виде доверительных интервалов, многократных прогонов, анализа разброса, не ограничиваясь одиночными числами. Также при описании динамических методов могут стать крайне полезными графики изменения KL, вознаграждений, loss-функций и распределений ответов.

---

Таким образом, работа представляет собой аккуратно выполненное исследование влияния комбинации SFT и RL на обучение компактной языковой модели в задачах математического рассуждения. Она иллюстрирует, что разумная конфигурация обучения способна улучшить качество даже в условиях ограниченных вычислительных ресурсов.

Однако новизна подхода пока выглядит ограниченной, а экспериментальная часть требует значительно более глубокой проработки. При добавлении подробностей, расширении анализа и уточнении вклада статья может стать ценным вкладом в область обучения малых LLM.
